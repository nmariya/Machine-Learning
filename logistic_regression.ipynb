{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFXZug066bJX"
      },
      "source": [
        "# Upload files in Google Colab\n",
        "If you are running this Jupyter Notebook on Google Colab, run this cell to upload the data files (train_inputs.csv, train_targets.csv, test_inputs.csv, test_targets.csv) in the colab virtual machine.  You will be prompted to select files that you would like to upload. \n",
        "\n",
        "If you are running this Jupyter Notebook on your computer, you do not need to run this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqBJV_Br4XeI",
        "outputId": "07d84307-7623-4918-80d6-cfd18a5e7169",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf83c71c-8a48-4f7d-a014-d6bd8b363f38\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bf83c71c-8a48-4f7d-a014-d6bd8b363f38\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_inputs.csv to test_inputs.csv\n",
            "Saving test_labels.csv to test_labels.csv\n",
            "Saving train_inputs.csv to train_inputs.csv\n",
            "Saving train_labels.csv to train_labels.csv\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/     test_labels.csv   train_labels.csv\n",
            "test_inputs.csv  train_inputs.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZDpxE4jmFwA"
      },
      "source": [
        "# Import libraries \n",
        "Do not use any other Python library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_1d0BPfmacB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6keYhcgi7nbf"
      },
      "source": [
        "# Function: load_logistic_regression_data\n",
        "\n",
        "This function loads the data for Logistic Regression from a local drive into RAM\n",
        "\n",
        "Outputs:\n",
        "\n",
        "*   **train_inputs**: numpy array of N training data points x M features\n",
        "*   **train_labels**: numpy array of N training labels\n",
        "*   **test_inputs**: numpy array of N' test data points x M features\n",
        "*   **test_labels**: numpy array of N' test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcG5U2lR7utt"
      },
      "source": [
        "def load_logistic_regression_data():\n",
        "  test_inputs = np.genfromtxt('test_inputs.csv', delimiter=',')\n",
        "  test_labels = np.genfromtxt('test_labels.csv', delimiter=',')\n",
        "  train_inputs = np.genfromtxt('train_inputs.csv', delimiter=',')\n",
        "  train_labels = np.genfromtxt('train_labels.csv', delimiter=',')\n",
        "  return train_inputs, train_labels, test_inputs, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZTxUMDM2PDx"
      },
      "source": [
        "# Function: sigmoid\n",
        "\n",
        "This function implements the logistic sigmoid.\n",
        "\n",
        "Input:\n",
        "*   **input**: vector of inputs (numpy array of floats)\n",
        "\n",
        "Output:\n",
        "*   **output**: vector of outputs (numpy array of floats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evR9GYnV3FmM"
      },
      "source": [
        "def sigmoid(input):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  #output = np.zeros(len(input))\n",
        "  output = 1/(1 + np.exp(-input))\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwLo3p4f8bTa"
      },
      "source": [
        "# Function: predict_logistic_regression\n",
        "\n",
        "This function uses a vector of weights to make predictions for a set of inputs.  The prediction for each data point is a distribution over the labels.  Assume that there are only two possible labels {0,1}.\n",
        "\n",
        "Inputs:\n",
        "*   **inputs**: matrix of input data points for which we want to make a prediction (numpy array of N data points x M+1 features)\n",
        "*   **weights**: vector of weights (numpy array of M+1 weights)\n",
        "\n",
        "Output:\n",
        "*   **predicted_probabilities**: matrix of predicted probabilities (numpy array of N data points x 2 labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX04_wClRqkV"
      },
      "source": [
        "def predict_logistic_regression(inputs, weights):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  predicted_probabilities = []\n",
        "  w_T = weights.transpose()#65X1\n",
        "  logi = sigmoid(np.dot(inputs,w_T)) #100x1\n",
        "  prob_zero = 1 - logi\n",
        "  predicted_probabilities = np.concatenate((prob_zero, logi), axis = 1)\n",
        "  return predicted_probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmfPN7K0RtQ5"
      },
      "source": [
        "# Function eval_logistic_regression\n",
        "\n",
        "This function evaluates a set of predictions by computing the negative log probabilities of the labels and the accuracy (percentage of correctly predicted labels).  Assume that there are only two possible labels {0,1}.  A data point is correctly labeled when the probability of the target label is >= 0.5.\n",
        "\n",
        "Inputs:\n",
        "*   **inputs**: matrix of input data points for which we will evaluate the predictions (numpy array of N data points x M+1 features)\n",
        "*   **weights**: vector of weights (numpy array of M+1 weights)\n",
        "*   **labels**: vector of target labels associated with the inputs (numpy array of N labels)\n",
        "\n",
        "Outputs:\n",
        "*   **neg_log_prob**: negative log probability of the set of predictions (float)\n",
        "*   **accuracy**: percentage of correctly labeled data points (float)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC14LEsvTxbu"
      },
      "source": [
        "def eval_logistic_regression(inputs, weights, labels):\n",
        "  #labels 100X1\n",
        "  # dummy assignment until the function is filled in\n",
        "  prob = predict_logistic_regression(inputs, weights) #100X2\n",
        "  logis = prob[:,1]\n",
        "  logis = logis.reshape(len(inputs),1)\n",
        "  logi = np.log(logis) #100X1\n",
        "  logist = np.log(1 - logis)\n",
        "  #neg_log_probs = ((logi*labels) + ((1-labels)*logist))\n",
        "  logi_t=logi.transpose()\n",
        "  logist_t=logist.transpose()\n",
        "  #neg_log_prob = neg_log_probs.sum()\n",
        "  neg_log_prob = -1*(np.dot(logi_t,labels)+ np.dot(logist_t,(1-labels)))\n",
        "  logi_a = logis + 0.01\n",
        "  logi_predicted = np.round(logi_a,0)\n",
        "  logi_predicted = logi_predicted.astype(int)\n",
        "  ## remember to reshape the logi predicted and label\n",
        "  tot = len(logi_predicted)\n",
        "  count = 0\n",
        "  for i,j in zip(logi_predicted,labels):\n",
        "    if i == j:\n",
        "      count = count + 1\n",
        "  accuracy = (count/tot)*100\n",
        "  return neg_log_prob, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7hZ4XVP4U4y"
      },
      "source": [
        "Function: initialize_weights\n",
        "\n",
        "This function initializes the weights uniformly at random in the interval [-0.05,0.05]\n",
        "\n",
        "Input:\n",
        "*   **n_weights**: # of weights to be initialized (integer)\n",
        "\n",
        "Output:\n",
        "*   **random_weights**: vector of weights (numpy array of floats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OjhevpV5FBg"
      },
      "source": [
        "def initialize_weights(n_weights):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  #random_weights = np.zeros(n_weights)\n",
        "  random_weights = np.random.uniform(-0.05, 0.05, n_weights)\n",
        "  random_weights = random_weights.reshape(1,65)\n",
        "  return random_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMAzC5xXT0H-"
      },
      "source": [
        "# Function train_logistic_regression\n",
        "\n",
        "This function optimizes a set of weights for logistic regression based on a training set.  Initialize the weights with the function initialize_weights.  Implement Newton's algorithm to optimize the weights.  Stop Newton's algorithm when the maximum change for all weights is less than 0.001 in two consecutive iterations. Assume that there are only two labels {0,1}.\n",
        "\n",
        "Inputs:\n",
        "*   **train_inputs**: matrix of input training points (numpy array of N data points x M+1 features)\n",
        "*   **train_labels**: vector of labels associated with the inputs (numpy array of N labels)\n",
        "*   **lambda_hyperparam**: lambda hyperparameter used to adjust the importance of the regularizer (scalar)\n",
        "\n",
        "Output:\n",
        "*   **weights**: vector of weights that have been optimized (numpy array of M+1 weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DkzoT5QVy41"
      },
      "source": [
        "def train_logistic_regression(train_inputs, train_labels, lambda_hyperparam):\n",
        "\n",
        "  # dummy assignment until the function is filled in\n",
        "  #weights = np.zeros(train_inputs.shape[1])\n",
        "  flag = 0\n",
        "  weights = initialize_weights(len(train_inputs[0])) ## 1*65\n",
        "  w_T = weights.transpose() ## 65*1\n",
        "  #print(\"wT\",w_T.shape)\n",
        "  #print(\"train_inputs\",train_inputs.shape)\n",
        "  ## train_inputs dimension 900*65\n",
        "  logi = sigmoid(np.dot(train_inputs,w_T)) ## 900 * 1\n",
        "  one_minus_logi = 1 - logi\n",
        "  Rnn_ = logi * one_minus_logi  ## 900 * 1 matrics\n",
        "  Rnn_ = Rnn_.reshape(1,len(train_inputs))\n",
        "  Rnn = np.diag(Rnn_[0])  ## 900 * 900\n",
        "  inputs_T = train_inputs.transpose() ## 65 * 900\n",
        "  H_stag = np.dot(inputs_T, Rnn) ## 65 * 900\n",
        "  H = np.dot(H_stag, train_inputs) ## 65 * 65\n",
        "  lambda_identity = lambda_hyperparam * np.identity(len(H)) ## 65 * 65\n",
        "  H_regularized = H + lambda_identity  ## 65 * 65\n",
        "  H_inv=np.linalg.inv(H_regularized)\n",
        "  grad = logi - train_labels #900X1\n",
        "  grad_T = grad.transpose() #1X900\n",
        "  gradient = np.dot(grad_T, train_inputs) #1X65\n",
        "  lambda_weights = lambda_hyperparam * weights #1X65\n",
        "  gradient_loss = gradient + lambda_weights #1X65\n",
        "  prod = np.dot(gradient_loss,H_inv) #1X65\n",
        "  while (np.amax(prod) >= 0.001 or flag == 0):\n",
        "    weights = weights - prod ## 1*65\n",
        "    w_T = weights.transpose()  ## 65*1\n",
        "    logi = sigmoid(np.dot(train_inputs,w_T))  ## 900*1\n",
        "    one_minus_logi = 1 - logi\n",
        "    Rnn_ = logi * one_minus_logi  ## 900*1\n",
        "    Rnn_ = Rnn_.reshape(1,len(train_inputs))  ## 900*1\n",
        "    Rnn = np.diag(Rnn_[0])  ## 900*900\n",
        "    inputs_T = train_inputs.transpose() ## 65*900\n",
        "    H_stag = np.dot(inputs_T, Rnn)  ## 65*900\n",
        "    H = np.dot(H_stag, train_inputs) ## 65*65\n",
        "    lambda_identity = lambda_hyperparam * np.identity(len(H))  ## 65*65\n",
        "    H_regularized = H + lambda_identity  ##  65*65\n",
        "    H_inv=np.linalg.inv(H_regularized)  ## 65*65\n",
        "    grad = logi - train_labels\n",
        "    grad_T = grad.transpose()\n",
        "    gradient = np.dot(grad_T, train_inputs)\n",
        "    lambda_weights = lambda_hyperparam * weights\n",
        "    gradient_loss = gradient + lambda_weights\n",
        "    prod = np.dot(gradient_loss,H_inv)\n",
        "    if np.amax(prod) < 0.001:\n",
        "      flag = 1\n",
        "    elif np.amax(prod) >= 0.001:\n",
        "      flag = 0\n",
        "  ##check the dimension of w has to be 1*M+1\n",
        "  return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYIbLxX7V2DW"
      },
      "source": [
        "# Function cross_validation_logistic_regression\n",
        "\n",
        "This function performs k-fold cross validation to determine the best lambda hyperparameter in logistic regression\n",
        "\n",
        "Inputs:\n",
        "*   **k_folds**: # of folds in cross-validation (integer)\n",
        "*   **hyperparameters**: list of hyperparameters where each hyperparameter is a different lambda value (list of floats)\n",
        "*   **inputs**: matrix of input points (numpy array of N data points by M+1 features)\n",
        "*   **labels**: vector of labels associated with the inputs (numpy array of N labels)\n",
        "\n",
        "Outputs:\n",
        "*   **best_hyperparam**: best lambda value for logistic regression (float)\n",
        "*   **best_neg_log_prob**: negative log probabilty achieved with best_hyperparam (float)\n",
        "*   **neg_log_probabilities**: vector of negative log probabilities for the corresponding hyperparameters (numpy array of floats)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZzoiZxLZMcV"
      },
      "source": [
        "def cross_validation_logistic_regression(k_folds, hyperparameters, inputs, labels):\n",
        "  \n",
        "  # dummy assignments until the function is filled in\n",
        "  best_hyperparam = 0\n",
        "  best_neg_log_prob = 0\n",
        "  neg_log_probabilities = []\n",
        "  accuracies_list = []\n",
        "  nlprob_list = []\n",
        "  param_list = []\n",
        "  for param in hyperparameters:\n",
        "    accuracies = []\n",
        "    nlp_list = []\n",
        "    param_list.append(param)\n",
        "    x = np.array_split(inputs, k_folds, axis=0)\n",
        "    x_label = np.array_split(labels, k_folds, axis=0)\n",
        "    for i in range(k_folds):\n",
        "      val_inputs = x[i]  ## 100 * 65\n",
        "      t = np.delete(x, i, axis=0)\n",
        "      t1 = t.transpose(2,0,1).reshape(65,-1)\n",
        "      train_inp = t1.transpose()  ## 900 * 65\n",
        "      val_labels = x_label[i]   ## 100 * 1\n",
        "      v_t = np.delete(x_label, i, axis=0)\n",
        "      v_t1 = v_t.transpose(2,0,1).reshape(1,-1)\n",
        "      train_lab = v_t1.transpose() ##  900 * 1\n",
        "      weights = train_logistic_regression(train_inp, train_lab, param) ##  1 * 65\n",
        "      n_l_p, acc = eval_logistic_regression(val_inputs, weights, val_labels)\n",
        "      accuracies.append(acc)\n",
        "      nlp_list.append(n_l_p)\n",
        "    avg_acc = (sum(accuracies)/len(accuracies))\n",
        "    accuracies_list.append(avg_acc)\n",
        "    avg_nlp = (sum(nlp_list)/len(nlp_list))\n",
        "    avg_nlp = avg_nlp[0][0]\n",
        "    nlprob_list.append(avg_nlp)\n",
        "    neg_log_probabilities.append(avg_nlp)\n",
        "  index = sorted(range(len(nlprob_list)), key = lambda k1: nlprob_list[k1])\n",
        "  best_hyperparam = param_list[index[0]]\n",
        "  best_neg_log_prob = neg_log_probabilities[index[0]]\n",
        "  return best_hyperparam, best_neg_log_prob, neg_log_probabilities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ah5AAayZfVU"
      },
      "source": [
        "# Function: plot_logistic_regression_neg_log_probabilities\n",
        "\n",
        "Function that plots the negative log probabilities for different lambda values (hyperparameters) in logistic regression based on cross validation\n",
        "\n",
        "Inputs:\n",
        "*   **neg_log_probabilities**: vector of negative log probabilities for the corresponding hyperparameters (numpy array of floats)\n",
        "*   **hyperparams**: list of hyperparameters where each hyperparameter is a different lambda value (list of floats)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh9qZuzMatsZ"
      },
      "source": [
        "def plot_logistic_regression_neg_log_probabilities(neg_log_probabilities,hyperparams):\n",
        "  plt.plot(hyperparams,neg_log_probabilities)\n",
        "  plt.ylabel('negative log probability')\n",
        "  plt.xlabel('lambda')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s21LRP5Qb3m8"
      },
      "source": [
        "# Main Logistic Regression code\n",
        "\n",
        "Load data (rescale the inputs to be in the [-1,1] range, add 1 at the end of each datapoint and rename the labels 5,6 to 0,1).\n",
        "Use k-fold cross validation to find the best lambda value for logistic regression.\n",
        "Plot the negative log probabilities for different lambda values.\n",
        "Test logistic regression with the best lambda value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njlK2bf7sycQ",
        "outputId": "05649269-78d3-4bb7-ac6e-fcb4aa519c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "# load data\n",
        "train_inputs, train_labels, test_inputs, test_labels = load_logistic_regression_data()\n",
        "\n",
        "# rescale inputs in the [-1,1] range\n",
        "train_inputs = (train_inputs - 8)/8\n",
        "test_inputs = (test_inputs - 8)/8\n",
        "\n",
        "# add 1 at the end of each data point\n",
        "train_inputs = np.concatenate((train_inputs,np.ones((train_inputs.shape[0],1))),1)\n",
        "test_inputs = np.concatenate((test_inputs,np.ones((test_inputs.shape[0],1))),1)\n",
        "\n",
        "# rename the classes 5,6 to 0,1\n",
        "train_labels = train_labels.astype(int) - 5\n",
        "train_labels = train_labels.reshape(1000,1)\n",
        "test_labels = test_labels.astype(int) - 5\n",
        "test_labels = test_labels.reshape(110,1)\n",
        "\n",
        "# lambda values to be evaluated by cross validation\n",
        "hyperparams = range(201) \n",
        "k_folds = 10\n",
        "best_lambda, best_neg_log_prob, neg_log_probabilities = cross_validation_logistic_regression(k_folds,hyperparams,train_inputs,train_labels)\n",
        "\n",
        "# plot results\n",
        "plot_logistic_regression_neg_log_probabilities(neg_log_probabilities,list(hyperparams))\n",
        "print('best lambda: ' + str (best_lambda))\n",
        "print('best cross validation negative log probability: ' + str(best_neg_log_prob))\n",
        "\n",
        "# train and evaluate with best lambda\n",
        "weights = train_logistic_regression(train_inputs,train_labels,best_lambda)\n",
        "neg_log_prob, accuracy = eval_logistic_regression(test_inputs, weights, test_labels)\n",
        "print('test accuracy: ' + str(accuracy))\n",
        "print('test negative log probability: ' + str(neg_log_prob))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "best lambda: 8\n",
            "best cross validation negative log probability: 37.6089026468225\n",
            "test accuracy: 88.18181818181819\n",
            "test negative log probability: [[33.29470074]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac-BjgFPrL-M"
      },
      "source": [
        "# Part II\n",
        "1.   Logistic regression classifier finds a linear seperator which is w'x_bar seperating at p = 0.5. Whereas, Knn finds a non-linear seperator.Expressivity of the seperator depends on the space of functions that each technique searches over to find a seperator. In that terms, logistic regression classifier model searches in a smaller space of functions for linear seperator. Because, linear seperators has to be a straight line in a 2D space and a hyperplane in higher dimension space. Whereas, Knn would search in a bigger space of non-linear functions(like, polynomials or curves) for a non-linear seperator. Thus, Knn classifier is more expressive that logistic regression classifier.\n",
        "\n",
        "> Under situations where there are no clear linear seperation between the classes of dataset, non-linear classifiers like Knn will be highly accurate if the training dataset is large enough. On the other hand, if the dataset has clear linear seperator (line or hyperplane), then a linear classifier like logistic regression classifier would perform better, with higher accuracy.\n",
        "\n",
        "> Noise could be yet another factor that decrease the performance of linera classifier. If we pay too much attention to noise when choosing the hyperplane, we tend to overfit and it will provide inaccurate results on a new data points.\n",
        "\n",
        "> Here, for outer digits dataset, the training set is linearly seperable which explains the higher accuracy of predicted class using logistic regression classifier(**88%**) rather than Knn classifier(**77%**).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRrZ_zlJ3duT"
      },
      "source": [
        "\n",
        "2.   Yes, the dataset is linearly seperable. The plot below shows the graph of negative log probability for the weights during iterations for weight optimization.\n",
        "\n",
        "> Here, we see that for a lambda value, the negative log probability value converges for weights as the weights gets optimized. This is only possible if the dataset in linearly seperable. Thus the convergence of the negative log probability to a global minimum shows the linear seperability of the train dataset used here.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSyENt_stLT0"
      },
      "source": [
        "def linear_seperability(train_inputs, train_labels, lambda_hyperparam):\n",
        "  flag = 0\n",
        "  nn = []\n",
        "  weights = initialize_weights(len(train_inputs[0])) ## 1*65\n",
        "  neglp, accc = eval_logistic_regression(train_inputs, weights, train_labels)\n",
        "  nn.append(neglp[0][0])\n",
        "  w_T = weights.transpose() ## 65*1\n",
        "  logi = sigmoid(np.dot(train_inputs,w_T)) ## 900 * 1\n",
        "  one_minus_logi = 1 - logi\n",
        "  Rnn_ = logi * one_minus_logi  ## 900 * 1 matrics\n",
        "  Rnn_ = Rnn_.reshape(1,len(train_inputs))\n",
        "  Rnn = np.diag(Rnn_[0])  ## 900 * 900\n",
        "  inputs_T = train_inputs.transpose() ## 65 * 900\n",
        "  H_stag = np.dot(inputs_T, Rnn) ## 65 * 900\n",
        "  H = np.dot(H_stag, train_inputs) ## 65 * 65\n",
        "  lambda_identity = lambda_hyperparam * np.identity(len(H)) ## 65 * 65\n",
        "  H_regularized = H + lambda_identity  ## 65 * 65\n",
        "  H_inv=np.linalg.inv(H_regularized)\n",
        "  grad = logi - train_labels #900X1\n",
        "  grad_T = grad.transpose() #1X900\n",
        "  gradient = np.dot(grad_T, train_inputs) #1X65\n",
        "  lambda_weights = lambda_hyperparam * weights #1X65\n",
        "  gradient_loss = gradient + lambda_weights #1X65\n",
        "  prod = np.dot(gradient_loss,H_inv) #1X65\n",
        "  while (np.amax(prod) >= 0.001 or flag == 0):\n",
        "    weights = weights - prod ## 1*65\n",
        "    neglp, accc = eval_logistic_regression(train_inputs, weights, train_labels)\n",
        "    nn.append(neglp[0][0])\n",
        "    w_T = weights.transpose()  ## 65*1\n",
        "    logi = sigmoid(np.dot(train_inputs,w_T))  ## 900*1\n",
        "    one_minus_logi = 1 - logi\n",
        "    Rnn_ = logi * one_minus_logi  ## 900*1\n",
        "    Rnn_ = Rnn_.reshape(1,len(train_inputs))  ## 900*1\n",
        "    Rnn = np.diag(Rnn_[0])  ## 900*900\n",
        "    inputs_T = train_inputs.transpose() ## 65*900\n",
        "    H_stag = np.dot(inputs_T, Rnn)  ## 65*900\n",
        "    H = np.dot(H_stag, train_inputs) ## 65*65\n",
        "    lambda_identity = lambda_hyperparam * np.identity(len(H))  ## 65*65\n",
        "    H_regularized = H + lambda_identity  ##  65*65\n",
        "    H_inv=np.linalg.inv(H_regularized)  ## 65*65\n",
        "    grad = logi - train_labels\n",
        "    grad_T = grad.transpose()\n",
        "    gradient = np.dot(grad_T, train_inputs)\n",
        "    lambda_weights = lambda_hyperparam * weights\n",
        "    gradient_loss = gradient + lambda_weights\n",
        "    prod = np.dot(gradient_loss,H_inv)\n",
        "    if np.amax(prod) < 0.001:\n",
        "      flag = 1\n",
        "    elif np.amax(prod) >= 0.001:\n",
        "      flag = 0  \n",
        "  return nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS4vYkL5wnkh",
        "outputId": "9f87e113-dd9a-4ac7-e2fa-a470f5455318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "iter = linear_seperability(train_inputs, train_labels, 4)\n",
        "plt.plot(range(len(iter)),iter)\n",
        "plt.ylabel('negative log probability')\n",
        "plt.xlabel('Iteration')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}